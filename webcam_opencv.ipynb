{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "webcam_opencv.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFid5G0URVyS"
      },
      "source": [
        "import cv2\r\n",
        "import imutils\r\n",
        "import numpy as np\r\n",
        "from PIL import Image\r\n",
        "from tensorflow.keras.models import load_model\r\n",
        "import imageio as ig\r\n",
        "\r\n",
        "model = load_model('emojirecog.hdf5')\r\n",
        "bg = None\r\n",
        "cam = cv2.VideoCapture(0)\r\n",
        "i = 1\r\n",
        "frame_no = 0\r\n",
        "top, right, bottom, left = 80, 400, 275, 640\r\n",
        "ra_weight = 1\r\n",
        "emoji_name = \"NONE\"\r\n",
        "labels = ['call_me','fingers_crossed','up','okay','paper','rock','rock_on','scissor','peace','thumbs_up']\r\n",
        "emojis = []\r\n",
        "for i in labels:\r\n",
        "    ran = cv2.imread(\"emojis/\" + i + \".png\",cv2.COLOR_BGR2RGB)\r\n",
        "    emojis.append(np.array(ran))\r\n",
        "   \r\n",
        "emojis = np.array(emojis)\r\n",
        "def run_avg(image, ra_weight):\r\n",
        "    global bg\r\n",
        "    if bg is None:\r\n",
        "        bg = image.copy().astype(\"float\")\r\n",
        "        return\r\n",
        "    cv2.accumulateWeighted(image, bg, ra_weight)\r\n",
        "\r\n",
        "\r\n",
        "def segment(image):\r\n",
        "    global bg\r\n",
        "    diff = cv2.absdiff(image,bg.astype(\"uint8\"))\r\n",
        "    threshold = cv2.threshold(diff, 50, 255, cv2.THRESH_BINARY)[1]\r\n",
        "    cnts = cv2.findContours(threshold.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\r\n",
        "    if len(cnts) == 0:\r\n",
        "        return\r\n",
        "    else:\r\n",
        "        segmented = max(cnts, key=cv2.contourArea)\r\n",
        "        return (threshold, segmented)\r\n",
        "\r\n",
        "\r\n",
        "while True:\r\n",
        "    ret, frame = cam.read()\r\n",
        "    frame = imutils.resize(frame, width=800)\r\n",
        "    frame = cv2.flip(frame, 1)\r\n",
        "    clone = frame.copy()\r\n",
        "    roi = frame[top:bottom, right:left]\r\n",
        "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\r\n",
        "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\r\n",
        "    number = \"0\"\r\n",
        "    if frame_no < 50:\r\n",
        "        run_avg(gray, ra_weight)\r\n",
        "    else:\r\n",
        "        hand = segment(gray)\r\n",
        "        if hand is not None:\r\n",
        "            (threshold, segmented) = hand\r\n",
        "            cv2.drawContours(clone, [segmented + (right, top)], -1, (255, 255, 0)) #right and top are to move the contours from (0,0)\r\n",
        "            im = Image.fromarray(threshold)\r\n",
        "            im = im.resize((240,200),Image.ANTIALIAS)\r\n",
        "            im = np.array(im)\r\n",
        "            im = np.expand_dims(im,axis = 2)\r\n",
        "            im = np.expand_dims(im,axis = 0)\r\n",
        "            #emo = model.predict_classes(im)[0]\r\n",
        "            cv2.imshow(\"emojis\",emojis[model.predict_classes(im)[0]])\r\n",
        "    cv2.rectangle(clone, (left, top), (right, bottom), (0,0,0), 2)\r\n",
        "    frame_no += 1\r\n",
        "   \r\n",
        "    #number = str(i-1)\r\n",
        "    cv2.putText(clone,number,(0,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\r\n",
        "    cv2.imshow(\"Video Feed\", clone)\r\n",
        "   \r\n",
        "    k = cv2.waitKey(1)\r\n",
        "    if k == 13:\r\n",
        "        break\r\n",
        "    elif k == 32:\r\n",
        "        cv2.imwrite('images/' + emoji_name + '/' + str(frame_no) + '.jpg', threshold)\r\n",
        "        i += 1\r\n",
        "\r\n",
        "cam.release()\r\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}